{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "import mne\n",
    "from mne.io import read_raw_fif, concatenate_raws\n",
    "from mne.datasets import visual_92_categories\n",
    "\n",
    "import gc\n",
    "import scipy\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "   trigger       condition  human  face  animal  natural\n",
      "0        0  human bodypart      1     0       1        1\n",
      "1        1  human bodypart      1     0       1        1\n",
      "2        2  human bodypart      1     0       1        1\n",
      "3        3  human bodypart      1     0       1        1\n",
      "4        4  human bodypart      1     0       1        1\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "data_path = visual_92_categories.data_path()\n",
    "\n",
    "# Define stimulus - trigger mapping\n",
    "fname = op.join(data_path, 'visual_stimuli.csv')\n",
    "conds = read_csv(fname)\n",
    "print(conds.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_trigger = 92\n",
    "conds = conds[:max_trigger]  # take the first 92 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = []\n",
    "for c in conds.values:\n",
    "    cond_tags = list(c[:2])\n",
    "    cond_tags += [('not-' if i == 0 else '') + conds.columns[k]\n",
    "                  for k, i in enumerate(c[2:], 2)]\n",
    "    conditions.append('/'.join(map(str, cond_tags)))\n",
    "#print(conditions[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id = dict(zip(conditions, conds.trigger + 1))\n",
    "#event_id['0/human bodypart/human/not-face/animal/natural']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1374 events found\n",
      "Event IDs: [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93 200 222 244]\n"
     ]
    }
   ],
   "source": [
    "n_runs = 1  # 4 for full data (use less to speed up computations)\n",
    "fname = op.join(data_path, 'sample_subject_%i_tsss_mc.fif') # only one subject\n",
    "raws = [read_raw_fif(fname % block, verbose='error')\n",
    "        for block in range(n_runs)]  # ignore filename warnings\n",
    "raw = concatenate_raws(raws)\n",
    "\n",
    "events = mne.find_events(raw, min_duration=.002)\n",
    "events = events[events[:, 2] <= max_trigger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "920 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 920 events and 501 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "picks = mne.pick_types(raw.info, meg=True)\n",
    "epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None,\n",
    "                    picks=picks, tmin=-.1, tmax=.4, preload=True) # epochs shape is (#epochs, #channels, #times)\n",
    "del raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.plot(n_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep50_300 = epochs.copy().crop(0.05, 0.3).get_data() # X\n",
    "base10_0 = epochs.copy().crop(-0.1, 0).get_data() # Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(920, 306, 251)\n",
      "(920, 306, 101)\n"
     ]
    }
   ],
   "source": [
    "print(ep50_300.shape)\n",
    "print(base10_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morlet Wavelet\n",
    "myfreqrange = np.array([2,120])\n",
    "Fs = 1000; # Hz, sampling rate\n",
    "# timedur = ep50_300.shape[2]/Fs # seconds, temporal duration\n",
    "timevec = np.linspace(0.05, 0.3, 251) # vector of time between 0 and timedur seconds\n",
    "timevec_gauss = np.linspace(-2, 2, 4001)\n",
    "lofreq = myfreqrange[0]\n",
    "hifreq = myfreqrange[1]\n",
    "\n",
    "NWavelets = 236\n",
    "NCycles = 7\n",
    "MyFreqs = np.linspace(lofreq, hifreq, NWavelets)\n",
    "MyMorletFamily = np.empty((0, 4001), float) # equivalent to \"clear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normpdf(x, mu=0, sigma=1):\n",
    "    u = float((x-mu) / abs(sigma))\n",
    "    y = np.exp(-u*u/2) / (np.sqrt(2*np.pi) * abs(sigma))\n",
    "    return y\n",
    "\n",
    "# Wavelet family\n",
    "for wnum in range(0, NWavelets):\n",
    "        myomega = 2 * np.pi * MyFreqs[wnum];\n",
    "        mysigma = NCycles/myomega\n",
    "        mygauss = np.array([normpdf(i,0,mysigma)\n",
    "                    for i in timevec_gauss])\n",
    "        mySig = np.exp(1j*myomega*timevec_gauss)\n",
    "        MyMorletFamily = np.append(MyMorletFamily, [mySig * mygauss], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(236, 4001)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "306"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(MyMorletFamily.shape)\n",
    "ep50_300.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fre_decomp(fftMEG, MyMorletFamily, NEvents, nconvolution, nshift):\n",
    "    fftGW = np.fft.fft(MyMorletFamily[:], nconvolution) # one dimensional transform?\n",
    "    fftconv = fftMEG * np.matlib.repmat(fftGW, NEvents, 1) # * for multiplying numpy arrays\n",
    "    conv_result = np.fft.ifft(fftconv, nconvolution,1)\n",
    "    conv_result = conv_result[:, (nshift):(conv_result.shape[1] - nshift)] # index?  \n",
    "    power = np.power(np.absolute(conv_result), 2)\n",
    "    del fftGW \n",
    "    del fftconv\n",
    "    del conv_result\n",
    "    gc.collect()\n",
    "    return power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = np.zeros((25))\n",
    "IDX\n",
    "x = timevec\n",
    "y = TimeBins\n",
    "line = 1\n",
    "distances = np.abs(x - y[line])\n",
    "distances.argmin()\n",
    "TimeBins.shape[0]\n",
    "\n",
    "# implements Matlab dsearchn\n",
    "def dsearchn(x,y):\n",
    "    IDX = np.zeros((y.shape[0]), int)\n",
    "    for line in range(0, y.shape[0]):\n",
    "        distances = np.abs(x - y[line])\n",
    "        distances.argmin()\n",
    "        IDX[line] = distances.argmin().astype(int)\n",
    "    return IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data for subj 1, attribute 'strdata':\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "# testing for data storage methods\n",
    "\n",
    "# dtype obj approach\n",
    "x = np.zeros(16, dtype = [('MEG_Power',int),('data',[]), ('MyFreqs',[]), \n",
    "                                ('TBins',[]), ('FBins',[]), ('EEGFeatures',[])])\n",
    "\n",
    "m = np.dtype([('name', np.unicode_, 16), ('grades', np.float64, (2,))])\n",
    "y = 1\n",
    "# print(type(m))\n",
    "# print(type(x))\n",
    "# print(type(x[0]))\n",
    "# print(x)\n",
    "# #x[0].MEG_Power = np.array(y)\n",
    "\n",
    "\n",
    "# nested dict approach\n",
    "testdata = {}\n",
    "testpower = np.array([1,2,3,4])#np.zeros((1,2,3,4))\n",
    "                    \n",
    "for subj in range(0,16):\n",
    "    testdata[subj] = {}\n",
    "    for chan in (0,2):\n",
    "        testdata[subj]['MEG_Power'] = testpower\n",
    "        testdata[subj]['bins'] = 1\n",
    "        testdata[subj]['strdata'] = \"string\"\n",
    "        \n",
    "#print(\"dictionary of subjs 1-16:\")\n",
    "#print(testdata)\n",
    "\n",
    "#print(\"data for subj 1:\")\n",
    "#print(testdata[0])\n",
    "\n",
    "print(\"data for subj 1, attribute 'strdata':\")\n",
    "print(testdata[0]['MEG_Power'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureBins(MEG_chan,TimeInds, FreqInds, NEvents):\n",
    "    NTBins = len(TimeInds)\n",
    "    NFBins = len(FreqInds)\n",
    "    this_featureset = np.zeros((NEvents, NFBins-1, NTBins-1))\n",
    "    for time in range (0, NTBins-1):\n",
    "        for freq in range (0, NFBins-1):\n",
    "            temp = MEG_chan[(FreqInds[freq]):(FreqInds[freq + 1]), (TimeInds[time]):(TimeInds[time + 1]), :]\n",
    "            # remove z-score if not operating w in participants-- MUST HAVE\n",
    "            # RIGHT UNIT OF SELECTION (from Spezio)\n",
    "            this_featureset[:, freq, time] = stats.zscore(np.median(np.squeeze(np.median(temp,0)),0)) # need py equivalent for: \n",
    "            # = zscore(median(squeeze(median(temp,1)),1))\n",
    "     \n",
    "    return this_featureset\n",
    "#     AllData(subj).EEGFeatures = this_featureset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for transferring time series data into frequency domain\n",
    "MEG_Power = np.zeros((920,306,8,25))\n",
    "\n",
    "# Baseline; divide by -.1 to 0\n",
    "\n",
    "\n",
    "# Time Bins\n",
    "TimeBins = np.linspace(0.05, 0.3, 26)\n",
    "\n",
    "# Frequency Bins\n",
    "FreqBins = np.array([2, 4, 8, 13, 20, 35, 55, 80, 120])\n",
    "\n",
    "Nchan = ep50_300.shape[1]\n",
    "#NTBins = len(TimeBins)\n",
    "#NFBins = len(FreqBins)\n",
    "nshift = int((timevec_gauss.size-1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# works but extremely slow\n",
    "\n",
    "# # initialize dtype array for data storage \n",
    "# # 16 participants are indexes, with fields given by dtype\n",
    "# # access values like AllData[2].MEG_Power = MEG_Power struct for participant 3\n",
    "# # i think\n",
    "# AllData = np.zeros(16, dtype = [('MEG_Power',[]),('data',[]), ('MyFreqs',[]), \n",
    "#                                 ('TBins',[]), ('FBins',[]), ('EEGFeatures',[])])\n",
    "\n",
    "\n",
    "# initialize dict for data storage\n",
    "#alldata_dict = {}\n",
    "\n",
    "# loop thru participants first (currently only working w 1)\n",
    "#for subj in range (0, 1):\n",
    "    \n",
    "    # create nested dict for each subj\n",
    "    #alldata_dict[subj] = {}\n",
    "TimeInds = dsearchn(timevec, TimeBins)\n",
    "FreqInds = dsearchn(MyFreqs, FreqBins)\n",
    "\n",
    "\n",
    "for chan in range(0, 15): # loop thru channels\n",
    "\n",
    "    # Signal Data\n",
    "    data = np.squeeze(ep50_300[:, chan, :])\n",
    "    NEvents = data.shape[0]\n",
    "    nconvolution = timevec_gauss.size + data.shape[1] - 1\n",
    "\n",
    "    # Baseline Data\n",
    "    pretrial_data = np.squeeze(base10_0[:, chan, :])\n",
    "    pretrial_nconvolution = timevec_gauss.size + pretrial_data.shape[1] - 1\n",
    "\n",
    "        #for enum in range(0, NEvents): # loop thru events\n",
    "\n",
    "    # Convert signal & pretrial to frequency domain\n",
    "    fftMEG = np.fft.fft(data[:,:], nconvolution)\n",
    "    pretrial_fftMEG = np.fft.fft(pretrial_data[:,:], pretrial_nconvolution)\n",
    "\n",
    "    MEG_chan =  np.empty((0, 251, 920))  \n",
    "\n",
    "    for wnum in range(0, NWavelets): # loop thru wavelets\n",
    "        #print(wnum)\n",
    "\n",
    "        #fftGW = np.fft.fft(MyMorletFamily[wnum,:],nconvolution) # one dimensional transform?\n",
    "        #pretrial_fftGW = np.fft.fft(MyMorletFamily[wnum,:], pretrial_nconvolution)\n",
    "\n",
    "        #pretrial_fftconv = pretrial_fftMEG * np.matlib.repmat(pretrial_fftGW,NEvents,1)\n",
    "        #pretrial_conv_result = np.fft.ifft(pretrial_fftconv,pretrial_nconvolution,1)\n",
    "        #pretrial_conv_result = pretrial_conv_result[:,(nshift):(pretrial_conv_result.shape[1] - nshift)]\n",
    "        #pretrial_power = np.power(np.absolute(pretrial_conv_result), 2)\n",
    "\n",
    "        #fftconv = fftMEG * np.matlib.repmat(fftGW,NEvents,1) # * for multiplying numpy arrays\n",
    "        #conv_result = np.fft.ifft(fftconv,nconvolution,1)\n",
    "        #conv_result = conv_result[:,(nshift):(conv_result.shape[1] - nshift)] # index? \n",
    "\n",
    "        pretrial_power = fre_decomp(pretrial_fftMEG, MyMorletFamily[wnum,:], NEvents, pretrial_nconvolution, nshift)\n",
    "        signal_power = fre_decomp(fftMEG, MyMorletFamily[wnum,:], NEvents, nconvolution, nshift)\n",
    "\n",
    "        normalized_MEG = np.transpose(signal_power)/np.matlib.repmat(np.median(np.transpose(pretrial_power), 0) , 251, 1)\n",
    "\n",
    "        MEG_chan = np.append(MEG_chan, [normalized_MEG], axis = 0) # numpy equivalent of transpose\n",
    "        \n",
    "    MEG_chan_Bins = FeatureBins(MEG_chan, TimeInds, FreqInds ,NEvents) # Feature set for the current electrode\n",
    "    # electrode x trial x wavelet x time\n",
    "    MEG_Power = np.append(MEG_Power, [MEG_chan_Bins], axis = 0)\n",
    "    \n",
    "    del MEG_chan\n",
    "    del MEG_chan_Bins\n",
    "    gc.collect() # clean memory      \n",
    "    print(chan)\n",
    "# timevec, TimeBins, MyFreqs, FreqBins were transposed in Matlab example\n",
    "# unsure if this works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 306, 8, 25)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MEG_Power.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeInds = dsearchn(timevec, TimeBins)\n",
    "FreqInds = dsearchn(MyFreqs, FreqBins)\n",
    "\n",
    "NTBins = len(TimeInds)\n",
    "NFBins = len(FreqInds)\n",
    "\n",
    "alldata_dict[subj]['MEG_Power'] = MEG_Power\n",
    "alldata_dict[subj]['MyFreqs'] = MyFreqs\n",
    "alldata_dict[subj]['TBins'] = TimeBins\n",
    "alldata_dict[subj]['FBins'] = FreqBins\n",
    "\n",
    "#     AllData[subj].MEG_Power = MEG_Power\n",
    "#     AllData[subj.MyFreqs = MyFreqs\n",
    "#     AllData[subj].TBins = TimeBins\n",
    "#     AllData[subj].FBins = FreqBins\n",
    "\n",
    "\n",
    "# need to replace obj.shape:\n",
    "#temp = np.zeros(temp.shape)\n",
    "#this_featureset = np.zeros(this_featureset.shape)\n",
    "\n",
    "# realllly unsure if this works\n",
    "for time in range (0, NTBins-1):\n",
    "    for freq in range (0, NFBins-1):\n",
    "        temp = MEG_Power[:, (FreqInds[freq]):(FreqInds[freq + 1]), \n",
    "                         (TimeInds[time]):(TimeInds[time + 1]), :]\n",
    "        # remove z-score if not operating w in participants-- MUST HAVE\n",
    "        # RIGHT UNIT OF SELECTION (from Spezio)\n",
    "        this_featureset[freq,time,:] # need py equivalent for: \n",
    "        # = zscore(median(squeeze(median(temp,1)),1))\n",
    "     \n",
    "    alldata_dict[subj]['EEGFeatures'] = this_featureset\n",
    "#     AllData(subj).EEGFeatures = this_featureset\n",
    "\n",
    "    \n",
    "#--------------------------------\n",
    "                #MEG_dB(wnum,:,:) = 10*log10(MEG_Power(wnum,:,:))\n",
    "\n",
    "                #baseline???\n",
    "                #for loops??\n",
    "                #np.fft.fft\n",
    "                # For numpy array, it seems that * is an element wise multiplication operator. But are we operating on np.array?\n",
    "\n",
    "\n",
    "#fast fourier transform (in numpy) (cohen's book) np.fft\n",
    "\n",
    "\n",
    "#one participant, for now  \n",
    "#wavelet number, then channel number\n",
    "\n",
    "\n",
    "#fft for each channel\n",
    "# then for each wavelet, going to do the fft of the gabor wavelet family, organize it by channel\n",
    "#element by element multiplication in python: numpy dot multiply\n",
    "#conv result using ifft , second dimension (,1) in python\n",
    "#nshift gives center\n",
    "#then baseline correct the power; conv result from 50-300 and divide from -.1 to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'this_featureset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-229-45e94327c28f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# remove z-score if not operating w in participants-- MUST HAVE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# RIGHT UNIT OF SELECTION (from Spezio)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mthis_featureset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# need py equivalent for:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0;31m# = zscore(median(squeeze(median(temp,1)),1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'this_featureset' is not defined"
     ]
    }
   ],
   "source": [
    "# works but extremely slow\n",
    "\n",
    "# # initialize dtype array for data storage \n",
    "# # 16 participants are indexes, with fields given by dtype\n",
    "# # access values like AllData[2].MEG_Power = MEG_Power struct for participant 3\n",
    "# # i think\n",
    "# AllData = np.zeros(16, dtype = [('MEG_Power',[]),('data',[]), ('MyFreqs',[]), \n",
    "#                                 ('TBins',[]), ('FBins',[]), ('EEGFeatures',[])])\n",
    "\n",
    "\n",
    "# initialize dict for data storage\n",
    "alldata_dict = {}\n",
    "\n",
    "# loop thru participants first (currently only working w 1)\n",
    "for subj in range (0, 1):\n",
    "    \n",
    "    # create nested dict for each subj\n",
    "    alldata_dict[subj] = {}\n",
    "\n",
    "    for chan in range(0, 1): # loop thru channels\n",
    "\n",
    "        # Signal Data\n",
    "        data = np.squeeze(ep50_300[:, chan, :])\n",
    "        NEvents = data.shape[0]\n",
    "        nconvolution = timevec_gauss.size + data.shape[1] - 1\n",
    "\n",
    "        # Baseline Data\n",
    "        pretrial_data = np.squeeze(base10_0[:, chan, :])\n",
    "        pretrial_nconvolution = timevec_gauss.size + pretrial_data.shape[1] - 1\n",
    "\n",
    "            #for enum in range(0, NEvents): # loop thru events\n",
    "\n",
    "        # Convert signal & pretrial to frequency domain\n",
    "        fftMEG = np.fft.fft(data[:,:], nconvolution)\n",
    "        pretrial_fftMEG = np.fft.fft(pretrial_data[:,:], pretrial_nconvolution)\n",
    "\n",
    "        MEG_chan =  np.empty((0, 251, 920))  \n",
    "\n",
    "        for wnum in range(0, NWavelets): # loop thru wavelets\n",
    "            print(wnum)\n",
    "\n",
    "            #fftGW = np.fft.fft(MyMorletFamily[wnum,:],nconvolution) # one dimensional transform?\n",
    "            #pretrial_fftGW = np.fft.fft(MyMorletFamily[wnum,:], pretrial_nconvolution)\n",
    "\n",
    "            #pretrial_fftconv = pretrial_fftMEG * np.matlib.repmat(pretrial_fftGW,NEvents,1)\n",
    "            #pretrial_conv_result = np.fft.ifft(pretrial_fftconv,pretrial_nconvolution,1)\n",
    "            #pretrial_conv_result = pretrial_conv_result[:,(nshift):(pretrial_conv_result.shape[1] - nshift)]\n",
    "            #pretrial_power = np.power(np.absolute(pretrial_conv_result), 2)\n",
    "\n",
    "            #fftconv = fftMEG * np.matlib.repmat(fftGW,NEvents,1) # * for multiplying numpy arrays\n",
    "            #conv_result = np.fft.ifft(fftconv,nconvolution,1)\n",
    "            #conv_result = conv_result[:,(nshift):(conv_result.shape[1] - nshift)] # index? \n",
    "\n",
    "            pretrial_power = fre_decomp(pretrial_fftMEG, MyMorletFamily[wnum,:], NEvents, pretrial_nconvolution, nshift)\n",
    "            signal_power = fre_decomp(fftMEG, MyMorletFamily[wnum,:], NEvents, nconvolution, nshift)\n",
    "\n",
    "            normalized_MEG = np.transpose(signal_power)/np.matlib.repmat(np.median(np.transpose(pretrial_power), 0) , 251, 1)\n",
    "\n",
    "            MEG_chan = np.append(MEG_chan, [normalized_MEG], axis = 0) # numpy equivalent of transpose\n",
    "       \n",
    "        # electrode x wavelet x time x trial\n",
    "        MEG_Power = np.append(MEG_Power, [MEG_chan], axis = 0)\n",
    "        \n",
    "        del MEG_chan\n",
    "        gc.collect() # clean memory      \n",
    "\n",
    "    # timevec, TimeBins, MyFreqs, FreqBins were transposed in Matlab example\n",
    "    # unsure if this works\n",
    "    TimeInds = dsearchn(timevec, TimeBins)\n",
    "    FreqInds = dsearchn(MyFreqs, FreqBins)\n",
    "\n",
    "    NTBins = len(TimeInds)\n",
    "    NFBins = len(FreqInds)\n",
    "    \n",
    "    alldata_dict[subj]['MEG_Power'] = MEG_Power\n",
    "    alldata_dict[subj]['MyFreqs'] = MyFreqs\n",
    "    alldata_dict[subj]['TBins'] = TimeBins\n",
    "    alldata_dict[subj]['FBins'] = FreqBins\n",
    "\n",
    "#     AllData[subj].MEG_Power = MEG_Power\n",
    "#     AllData[subj.MyFreqs = MyFreqs\n",
    "#     AllData[subj].TBins = TimeBins\n",
    "#     AllData[subj].FBins = FreqBins\n",
    "  \n",
    "\n",
    "    # need to replace obj.shape:\n",
    "    #temp = np.zeros(temp.shape)\n",
    "    #this_featureset = np.zeros(this_featureset.shape)\n",
    "    \n",
    "    # realllly unsure if this works\n",
    "    for time in range (0, NTBins-1):\n",
    "        for freq in range (0, NFBins-1):\n",
    "            temp = MEG_Power[:, (FreqInds[freq]):(FreqInds[freq + 1]), \n",
    "                             (TimeInds[time]):(TimeInds[time + 1]), :]\n",
    "            # remove z-score if not operating w in participants-- MUST HAVE\n",
    "            # RIGHT UNIT OF SELECTION (from Spezio)\n",
    "            this_featureset[freq,time,:] # need py equivalent for: \n",
    "            # = zscore(median(squeeze(median(temp,1)),1))\n",
    "     \n",
    "    alldata_dict[subj]['EEGFeatures'] = this_featureset\n",
    "#     AllData(subj).EEGFeatures = this_featureset\n",
    "\n",
    "    \n",
    "#--------------------------------\n",
    "                #MEG_dB(wnum,:,:) = 10*log10(MEG_Power(wnum,:,:))\n",
    "\n",
    "                #baseline???\n",
    "                #for loops??\n",
    "                #np.fft.fft\n",
    "                # For numpy array, it seems that * is an element wise multiplication operator. But are we operating on np.array?\n",
    "\n",
    "\n",
    "#fast fourier transform (in numpy) (cohen's book) np.fft\n",
    "\n",
    "\n",
    "#one participant, for now  \n",
    "#wavelet number, then channel number\n",
    "\n",
    "\n",
    "#fft for each channel\n",
    "# then for each wavelet, going to do the fft of the gabor wavelet family, organize it by channel\n",
    "#element by element multiplication in python: numpy dot multiply\n",
    "#conv result using ifft , second dimension (,1) in python\n",
    "#nshift gives center\n",
    "#then baseline correct the power; conv result from 50-300 and divide from -.1 to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 236, 251, 920)\n"
     ]
    }
   ],
   "source": [
    "print(alldata_dict[0]['MEG_Power'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify using the average signal in the window 50ms to 300ms\n",
    "# to focus the classifier on the time interval with best SNR.\n",
    "clf = make_pipeline(StandardScaler(),\n",
    "                    LogisticRegression(C=1, solver='liblinear',\n",
    "                                       multi_class='auto'))\n",
    "\n",
    "#y = epochs.events[:, 2]\n",
    "y_sup = (epochs.events[:, 2] > 48).astype(int) #set up superordinate classification label. \n",
    "classes = set(y_sup) \n",
    "\n",
    "#cv = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
    "\n",
    "# Compute confusion matrix for each cross-validation fold\n",
    "#y_pred = np.zeros((len(y_sup), len(classes)))\n",
    "#for train, test in cv.split(ep50_300, y_sup):\n",
    "    # Fit\n",
    " #   clf.fit(ep50_300[train], y_sup[train])\n",
    "    # Probabilistic prediction (necessary for ROC-AUC scoring metric)\n",
    "  #  y_pred[test] = clf.predict_proba(ep50_300[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-18e5d6c61204>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my_sup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m48\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_sup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclasses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'classes' is not defined"
     ]
    }
   ],
   "source": [
    "y_sup = (epochs.events[:, 2] > 48).astype(int)\n",
    "y_sup.shape\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regularized Regression Lasso / Ridge / Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67340695, 0.32659305],\n",
       "       [0.32659305, 0.67340695]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion = np.zeros((len(classes), len(classes)))\n",
    "for ii, train_class in enumerate(classes):\n",
    "    for jj in range(ii, len(classes)):\n",
    "        confusion[ii, jj] = roc_auc_score(y_sup == train_class, y_pred[:, jj])\n",
    "        confusion[jj, ii] = confusion[ii, jj]\n",
    "confusion  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
