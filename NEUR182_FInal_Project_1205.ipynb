{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolving human object recognition: A time-frequency analysis\n",
    "\n",
    "Vani, Ben, & Jeanne\n",
    "\n",
    "NEUR182: Machine Learning w/ Neural Signal\n",
    "\n",
    "Prof. Michael Spezio\n",
    "\n",
    "Fall 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import gc # for memory cleaning\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "import mne\n",
    "from mne.io import read_raw_fif, concatenate_raws\n",
    "from mne.datasets import visual_92_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[function definitions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performs frequency decomposition\n",
    "# returns power as np.ndarray\n",
    "\n",
    "def fre_decomp(fftMEG, MorletFamily, nEvents, nConvolution, nShift):\n",
    "    fftGW = np.fft.fft(MorletFamily[:], nConvolution)\n",
    "    fftconv = fftMEG * np.matlib.repmat(fftGW, nEvents, 1)\n",
    "    conv_result = np.fft.ifft(fftconv, nConvolution, 1)\n",
    "    conv_result = conv_result[:, (nShift):(conv_result.shape[1] - nShift)]\n",
    "    power = np.power(np.absolute(conv_result), 2)\n",
    "    \n",
    "    del fftGW \n",
    "    del fftconv\n",
    "    del conv_result\n",
    "    gc.collect()\n",
    "    \n",
    "    return power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implements Matlab's dsearchn()\n",
    "# returns indices of nearest points as np.ndarray\n",
    "\n",
    "def dsearchn(x, y):\n",
    "    dist = np.zeros((y.shape[0]), int)\n",
    "    \n",
    "    for line in range(0, y.shape[0]):\n",
    "        distances = np.abs(x - y[line])\n",
    "        distances.argmin()\n",
    "        dist[line] = distances.argmin().astype(int)\n",
    "    \n",
    "    return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implements Matlab's normpdf()\n",
    "# returns pdf as float\n",
    "\n",
    "def normpdf(x, mu=0, sigma=1):\n",
    "    u = float((x-mu) / abs(sigma))\n",
    "    y = np.exp(-u*u/2) / (np.sqrt(2*np.pi) * abs(sigma))\n",
    "    \n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performs feature engineering\n",
    "# returns feature set as np.ndarray\n",
    "\n",
    "def FeatureBins(MEG_chan, timeIndx, freqIndx, nEvents):\n",
    "    nTBins = len(timeIndx)\n",
    "    nFBins = len(freqIndx)\n",
    "    featureset = np.zeros((nEvents, nFBins-1, nTBins-1))\n",
    "   \n",
    "    for time in range (0, nTBins-1):\n",
    "        for freq in range (0, nFBins-1):\n",
    "            temp = MEG_chan[(freqIndx[freq]):(freqIndx[freq + 1]), \n",
    "                            (timeIndx[time]):(timeIndx[time + 1]),:]\n",
    "            featureset[:, freq, time] = stats.zscore(np.median(np.squeeze(np.median(temp,0)),0))\n",
    "     \n",
    "    return featureset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[begin data shaping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = visual_92_categories.data_path()\n",
    "\n",
    "# define stimulus-trigger mapping (code from King, Leppakangas, & Gramfort)\n",
    "fname = op.join(data_path, 'visual_stimuli.csv')\n",
    "conds = read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the first 92 rows\n",
    "max_trigger = 92\n",
    "conds = conds[:max_trigger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = []\n",
    "for c in conds.values:\n",
    "    cond_tags = list(c[:2])\n",
    "    cond_tags += [('not-' if i == 0 else '') + conds.columns[k]\n",
    "                  for k, i in enumerate(c[2:], 2)]\n",
    "    conditions.append('/'.join(map(str, cond_tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id = dict(zip(conditions, conds.trigger + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1374 events found\n",
      "Event IDs: [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93 200 222 244]\n"
     ]
    }
   ],
   "source": [
    "nRuns = 1  # 4 for full data (use less to speed up computations)\n",
    "fname = op.join(data_path, 'sample_subject_%i_tsss_mc.fif')\n",
    "\n",
    "raws = [read_raw_fif(fname % block, verbose='error')\n",
    "        for block in range(0, nRuns)]  # ignore filename warnings\n",
    "raw = concatenate_raws(raws)\n",
    "\n",
    "events = mne.find_events(raw, min_duration=.002)\n",
    "events = events[events[:, 2] <= max_trigger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "920 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 920 events and 501 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "picks = mne.pick_types(raw.info, meg=True)\n",
    "epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None,\n",
    "                    picks=picks, tmin=-.1, tmax=.4, preload=True)\n",
    "del raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual representation of epochs data structure\n",
    "#epochs.plot(n_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep50_300 = epochs.copy().crop(0.05, 0.3).get_data()\n",
    "base10_0 = epochs.copy().crop(-0.1, 0).get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[end data shaping] [begin data processing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize elements for Morlet wavelets\n",
    "nWavelets = 236\n",
    "freq_range = np.array([2,120])\n",
    "lofreq = freq_range[0]\n",
    "hifreq = freq_range[1]\n",
    "freqs = np.linspace(lofreq, hifreq, nWavelets)\n",
    "Fs = 1000 # Hz, sampling rate\n",
    "timevec = np.linspace(0.05, 0.3, 251)\n",
    "timevec_gauss = np.linspace(-2, 2, 4001)\n",
    "nCycles = 7\n",
    "\n",
    "MorletFamily = np.empty((0, 4001), float)\n",
    "\n",
    "# create complex wavelet family\n",
    "for wavelet in range(0, nWavelets):\n",
    "        omega = 2 * np.pi * freqs[wavelet];\n",
    "        sigma = nCycles / omega\n",
    "        gauss = np.array([normpdf(i,0, sigma)\n",
    "                    for i in timevec_gauss])\n",
    "        sig = np.exp(1j * omega * timevec_gauss)\n",
    "        MorletFamily = np.append(MorletFamily, [sig * gauss], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time indices are:\n",
      "[  0  10  20  30  40  50  60  70  80  90 100 110 120 130 140 150 160 170\n",
      " 180 190 200 210 220 230 240 250]\n",
      "frequency indices are:\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# initalize elements for transferring time series to frequency domain\n",
    "nEvents = ep50_300.shape[0]\n",
    "MEG_Power = np.zeros((nEvents,306,8,25))\n",
    "nChan = ep50_300.shape[1]\n",
    "nShift = int((timevec_gauss.size-1)/2)\n",
    "\n",
    "# time & frequency bins\n",
    "TimeBins = np.linspace(0.05, 0.3, 26)\n",
    "FreqBins = np.array([2, 4, 8, 13, 20, 35, 55, 80, 120])\n",
    "timeIndx = dsearchn(timevec, TimeBins)\n",
    "freqIndx = dsearchn(freqs, FreqBins)\n",
    "\n",
    "print(\"time indices are:\") \n",
    "print(timeIndx)\n",
    "print(\"\\nfrequency indices are:\")\n",
    "print(freqIndx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-0d3f7d97efb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mwavelet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnWavelets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         pre_power = fre_decomp(pre_fftMEG, MorletFamily[wavelet,:], nEvents, \n\u001b[0;32m---> 23\u001b[0;31m                                pre_nConvolution, nShift)\n\u001b[0m\u001b[1;32m     24\u001b[0m         sig_power = fre_decomp(fftMEG, MorletFamily[wavelet,:], nEvents, \n\u001b[1;32m     25\u001b[0m                                nConvolution, nShift)\n",
      "\u001b[0;32m<ipython-input-2-64cbd6650328>\u001b[0m in \u001b[0;36mfre_decomp\u001b[0;34m(fftMEG, MorletFamily, nEvents, nConvolution, nShift)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mfftconv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mconv_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpower\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# *** loop over channels ***\n",
    "for chan in range(0, nChan): \n",
    "\n",
    "    # process baseline data\n",
    "    pre_data = np.squeeze(base10_0[:,chan,:])\n",
    "    pre_nConvolution = timevec_gauss.size + pre_data.shape[1] - 1\n",
    "    \n",
    "    # process signal data\n",
    "    data = np.squeeze(ep50_300[:,chan,:])\n",
    "    nEvents = data.shape[0]\n",
    "    nConvolution = timevec_gauss.size + data.shape[1] - 1\n",
    "\n",
    "    # convert signal & baseline to frequency domain\n",
    "    pre_fftMEG = np.fft.fft(pre_data[:,:], pre_nConvolution)\n",
    "    fftMEG = np.fft.fft(data[:,:], nConvolution)\n",
    "\n",
    "    MEG_chan =  np.empty((0, 251, nEvents))  \n",
    "\n",
    "    \n",
    "    # ****** loop over wavelets *******\n",
    "    for wavelet in range(0, nWavelets):\n",
    "        pre_power = fre_decomp(pre_fftMEG, MorletFamily[wavelet,:], nEvents, \n",
    "                               pre_nConvolution, nShift)\n",
    "        sig_power = fre_decomp(fftMEG, MorletFamily[wavelet,:], nEvents, \n",
    "                               nConvolution, nShift)\n",
    "\n",
    "        normal_MEG = (np.transpose(sig_power) / \n",
    "                      np.matlib.repmat(np.median(np.transpose(pre_power), 0), 251, 1))\n",
    "        MEG_chan = np.append(MEG_chan, [normal_MEG], axis = 0)\n",
    "       \n",
    "    \n",
    "    # store feature set for current electrode\n",
    "    MEG_chanBins = FeatureBins(MEG_chan, timeIndx, freqIndx, nEvents)      \n",
    "    MEG_Power[:,chan,:,:] = MEG_chanBins  # [electrode x trial x wavelet x time]\n",
    "    \n",
    "    #del MEG_chan\n",
    "    #del MEG_chanBins\n",
    "    #gc.collect()     \n",
    "    \n",
    "    print(chan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[end data processing] [begin data analysis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 306, 8, 25)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data features\n",
    "this_featureset = np.load('Pt1Featureset.npy')\n",
    "this_featureset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(920,)\n"
     ]
    }
   ],
   "source": [
    "# create labels\n",
    "y_sup = (epochs.events[:, 2] > 48).astype(int) # set up superordinate classification label\n",
    "print(y_sup.shape)\n",
    "#print(y_sup)\n",
    "classes = set(y_sup) \n",
    "#print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "Feats_train, Feats_test, OV_train, OV_test = train_test_split(this_featureset, y_sup, test_size=0.3, random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Feats_train', Feats_train)\n",
    "np.save('Feats_test', Feats_test)\n",
    "np.save('OV_train', OV_train)\n",
    "np.save('OV_test', OV_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feats_train = np.load('Feats_train.npy')\n",
    "Feats_test = np.load('Feats_test.npy')\n",
    "OV_train = np.load('OV_train.npy')\n",
    "OV_test = np.load('OV_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(644, 306, 8, 25)\n",
      "(276, 306, 8, 25)\n"
     ]
    }
   ],
   "source": [
    "print(Feats_train.shape)\n",
    "print(Feats_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feats_train = np.reshape(Feats_train, (644, 61200))\n",
    "Feats_test = np.reshape(Feats_test, (276, 61200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(644, 61200)\n",
      "(276, 61200)\n"
     ]
    }
   ],
   "source": [
    "print(Feats_train.shape)\n",
    "print(Feats_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess correlation between features to check for multicollinearity\n",
    "# PVsCorrMat = np.corrcoef(Feats_train, rowvar = False)\n",
    "# PVsCoDMat = np.power(PVsCorrMat, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(PVsCodDMat.shape)\n",
    "# print(PVsCodDMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NEUR182_tf2/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:188: LinAlgWarning: Ill-conditioned matrix (rcond=5.36879e-17): result may not be accurate.\n",
      "  overwrite_a=False)\n",
      "/opt/anaconda3/envs/NEUR182_tf2/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:188: LinAlgWarning: Ill-conditioned matrix (rcond=5.11012e-17): result may not be accurate.\n",
      "  overwrite_a=False)\n",
      "/opt/anaconda3/envs/NEUR182_tf2/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:188: LinAlgWarning: Ill-conditioned matrix (rcond=5.46737e-17): result may not be accurate.\n",
      "  overwrite_a=False)\n",
      "/opt/anaconda3/envs/NEUR182_tf2/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:188: LinAlgWarning: Ill-conditioned matrix (rcond=6.88205e-17): result may not be accurate.\n",
      "  overwrite_a=False)\n",
      "/opt/anaconda3/envs/NEUR182_tf2/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:188: LinAlgWarning: Ill-conditioned matrix (rcond=5.37227e-17): result may not be accurate.\n",
      "  overwrite_a=False)\n"
     ]
    }
   ],
   "source": [
    "# fit lasso, ridge, and the ElasticNet models using a tuning approach over \n",
    "# hyperparameter alpha (lambda)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing, model_selection, linear_model, metrics\n",
    "\n",
    "# tune reg models using validate proportion of train set\n",
    "def TuningModels(models, X, Y, val_size, iterations = 100):\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    results = {}\n",
    "    for i in models:\n",
    "        metric_train = []\n",
    "        metric_val = []\n",
    "        for j in range(iterations):\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X,Y,test_size = val_size)\n",
    "            metric_val.append(metrics.mean_squared_error(y_val,\n",
    "                                                     models[i].fit(X_train,\n",
    "                                                                   y_train).predict(X_val)))\n",
    "            metric_train.append(metrics.mean_squared_error(y_train,\n",
    "                                                       models[i].fit(X_train, \n",
    "                                                                     y_train).predict(X_train)))\n",
    "        results[i] = [np.mean(metric_train), np.mean(metric_val)]\n",
    "    return results\n",
    "\n",
    "# alpha = penalty for deviance\n",
    "lasso_params = {'alpha':np.linspace(1e-5,1e-2,30)}\n",
    "ridge_params = {'alpha':np.linspace(1e-10,20,50)}\n",
    "\n",
    "\n",
    "models = {'Lasso': GridSearchCV(linear_model.Lasso(tol = 1e-3, random_state=47), \n",
    "                                param_grid=lasso_params).fit(Feats_train, OV_train).best_estimator_,\n",
    "          'Ridge': GridSearchCV(linear_model.Ridge(tol = 1e-3, random_state = 47),\n",
    "                                 param_grid=ridge_params).fit(Feats_train, OV_train).best_estimator_}\n",
    "\n",
    "MyRes = TuningModels(models, Feats_train, OV_train, val_size = 0.2, iterations = 47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lasso': [0.012464100328162519, 0.3018793766747705], 'Ridge': [7.098829730860406e-08, 0.2628597931900838]}\n",
      "Optimal alpha for LASSO is 0.01\n",
      "Optimal alpha for Ridge is 20.0\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "print(MyRes)\n",
    "\n",
    "# print optimal parameters after tuning\n",
    "print('Optimal alpha for LASSO is ' + str(models['Lasso'].alpha))\n",
    "print('Optimal alpha for Ridge is ' + str(models['Ridge'].alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Rsq Error = 1.1323441531983698\n",
      "Ridge Rsq Error = 1.1733581292235875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "LassoModel = Lasso(tol = 1e-3, random_state = 47, alpha = models['Lasso'].alpha)\n",
    "LassoModel.fit(Feats_train, OV_train)\n",
    "LassoPredictTest = LassoModel.predict(Feats_test)\n",
    "LassoRSqError = 1 - metrics.explained_variance_score(OV_test,LassoPredictTest)\n",
    "print('Lasso Rsq Error = ' + str(LassoRSqError))\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "RidgeModel = Ridge(tol = 1e-3, random_state = 47, alpha = models['Ridge'].alpha)\n",
    "RidgeModel.fit(Feats_train, OV_train)\n",
    "RidgePredictTest = RidgeModel.predict(Feats_test)\n",
    "RidgeRSqError = 1 - metrics.explained_variance_score(OV_test,RidgePredictTest)\n",
    "print('Ridge Rsq Error = ' + str(RidgeRSqError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
